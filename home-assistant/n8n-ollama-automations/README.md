# Home Assistant + n8n + Ollama: Automatizaciones con IA Local

Stack completo para crear automatizaciones inteligentes en tu hogar usando **Home Assistant**, **n8n** y **Ollama** (LLM local). Todo 100% self-hosted, sin costes mensuales, con tus datos bajo control.

## üéØ ¬øQu√© incluye?

- **Docker Compose completo** para levantar todo el stack
- **5 workflows n8n funcionales** listos para importar
- Integraci√≥n Home Assistant ‚Üî n8n ‚Üî Ollama
- Decisiones contextuales con IA (clima, hora, presencia)
- Control por voz en lenguaje natural
- Optimizaci√≥n energ√©tica autom√°tica
- Detecci√≥n de anomal√≠as de seguridad
- Sistema de notificaciones priorizadas por IA

## üìã Requisitos

- Docker + Docker Compose
- 4GB RAM m√≠nimo (8GB recomendado para modelos LLM)
- 20GB espacio disco para modelos Ollama
- (Opcional) GPU NVIDIA para inferencia m√°s r√°pida

## üöÄ Instalaci√≥n R√°pida

### 1. Clonar y levantar servicios

```bash
# Clonar este repositorio
git clone https://github.com/ziruelen/learningaiagents.git
cd learningaiagents/home-assistant/n8n-ollama-automations

# Levantar todos los servicios
docker-compose up -d
```

### 2. Configurar Home Assistant

Accede a `http://tu-ip:8123` y completa el wizard inicial.

Edita `homeassistant/configuration.yaml` y a√±ade:

```yaml
# Habilitar API REST
api:

# Permitir CORS para n8n
http:
  cors_allowed_origins:
    - http://localhost:5678
    - http://tu-ip:5678

# Webhooks para n8n
automation: !include automations.yaml
```

Reinicia Home Assistant.

### 3. Generar token API Home Assistant

1. Ve a tu perfil en Home Assistant
2. Scroll hasta "Tokens de acceso de larga duraci√≥n"
3. Crea un nuevo token y c√≥pialo

### 4. Configurar n8n

Accede a `http://tu-ip:5678`

**Configurar credenciales Home Assistant:**

1. Ve a Credentials ‚Üí New
2. Selecciona "Home Assistant"
3. Nombre: `Home Assistant Local`
4. Host: `http://homeassistant:8123` (si usas Docker) o `http://tu-ip:8123`
5. Access Token: pega el token del paso anterior
6. Guarda

### 5. Descargar modelo Ollama

```bash
# Descargar modelo Llama 3.2 (recomendado, 2GB)
docker exec -it ollama ollama pull llama3.2

# O un modelo m√°s peque√±o si tienes poca RAM
docker exec -it ollama ollama pull llama3.2:1b

# Verificar que funciona
docker exec -it ollama ollama run llama3.2 "Hola, ¬øfuncionas?"
```

### 6. Importar workflows n8n

1. En n8n, ve a Workflows ‚Üí Import from File
2. Importa cada archivo de la carpeta `workflows/`:
   - `1-llegar-casa-contexto.json`
   - `2-comando-voz-natural.json`
   - `3-optimizacion-energia.json`
   - `4-notificaciones-inteligentes.json`
   - `5-seguridad-anomalias.json`

3. En cada workflow, verifica que las credenciales de Home Assistant est√©n correctamente asignadas
4. Activa los workflows que quieras usar

## üìö Descripci√≥n de Workflows

### 1Ô∏è‚É£ Automatizaci√≥n Llegada Casa con Contexto IA

**Qu√© hace:** Cuando llegas a casa, la IA analiza clima exterior, temperatura interior y hora del d√≠a para decidir qu√© hacer.

**Ejemplo:**
- Si hace fr√≠o afuera ‚Üí Enciende calefacci√≥n
- Si es de noche ‚Üí Enciende luces
- Te env√≠a notificaci√≥n: "Bienvenido. He encendido la calefacci√≥n a 21¬∞C porque hace 5¬∞C afuera"

**Entidades necesarias:**
- `person.usuario` (tu persona en HA)
- `weather.home` (integraci√≥n meteorol√≥gica)
- `sensor.interior_temperature`
- `light.salon`
- `climate.termostato`

### 2Ô∏è‚É£ Control por Voz Natural con IA

**Qu√© hace:** Webhook que recibe comandos en lenguaje natural y la IA los interpreta para ejecutar acciones.

**Ejemplos de uso:**

```bash
# Encender luces del sal√≥n
curl -X POST http://tu-ip:5678/webhook/voice-command \
  -H "Content-Type: application/json" \
  -d '{"text": "Enciende las luces del sal√≥n"}'

# Ajustar temperatura
curl -X POST http://tu-ip:5678/webhook/voice-command \
  -H "Content-Type: application/json" \
  -d '{"text": "Pon la calefacci√≥n a 22 grados"}'

# Bajar persianas
curl -X POST http://tu-ip:5678/webhook/voice-command \
  -H "Content-Type: application/json" \
  -d '{"text": "Baja las persianas del dormitorio"}'
```

**Integraci√≥n con asistentes de voz:**
- Puedes llamar este webhook desde Google Home, Alexa o Siri usando rutinas

### 3Ô∏è‚É£ Optimizaci√≥n Energ√©tica con IA

**Qu√© hace:** Cada hora, analiza consumo el√©ctrico, precio de la luz y presencia en casa para optimizar.

**Acciones autom√°ticas:**
- Apaga dispositivos en standby si precio es alto y no hay nadie
- Ajusta calefacci√≥n bas√°ndose en precio/hora
- Apaga luces innecesarias
- Te notifica el ahorro estimado

**Entidades necesarias:**
- `sensor.energia_consumo_actual`
- `sensor.precio_electricidad` (integraci√≥n PVPC/precio luz)
- `binary_sensor.presence_home`
- `switch.enchufes_standby`
- `climate.termostato`

### 4Ô∏è‚É£ Notificaciones Inteligentes Priorizadas

**Qu√© hace:** Captura TODOS los eventos de Home Assistant y la IA decide cu√°les son importantes y c√≥mo notificarte.

**Niveles de prioridad:**
- **Cr√≠tico:** Alarma sonora + notificaci√≥n push inmediata
- **Alto:** Notificaci√≥n push normal
- **Medio/Bajo:** Notificaci√≥n silenciosa o log

**Ejemplos:**
- Puerta abierta a las 3 AM ‚Üí Cr√≠tico
- Temperatura >30¬∞C ‚Üí Alto
- Luz encendida 2h ‚Üí Medio
- Sensor bater√≠a baja ‚Üí Bajo

**Entidades necesarias:**
- `binary_sensor.modo_no_molestar`
- Servicio de notificaciones configurado (ej: `notify.mobile_app`)

### 5Ô∏è‚É£ Detecci√≥n Anomal√≠as Seguridad con IA

**Qu√© hace:** Cada 15 minutos, analiza patrones de actividad (red, puertas, intentos de login) y detecta comportamientos anormales.

**Anomal√≠as que detecta:**
- Picos inusuales de tr√°fico de red (posible malware)
- Puertas/ventanas abiertas en horarios raros
- M√∫ltiples intentos de login fallidos
- Actividad cuando no deber√≠a haber nadie

**Acciones autom√°ticas:**
- Riesgo cr√≠tico ‚Üí Activa modo seguridad + captura c√°maras + alerta push
- Riesgo alto ‚Üí Notificaci√≥n inmediata
- Riesgo medio ‚Üí Log y notificaci√≥n silenciosa

**Entidades necesarias:**
- `sensor.consumo_red`
- `binary_sensor.puertas_ventanas`
- `sensor.intentos_login`
- `camera.todas` (grupo de c√°maras)

## ‚öôÔ∏è Personalizaci√≥n

### Cambiar modelo de IA

Edita los workflows y modifica el campo `"model": "llama3.2"` por otro:

```json
{
  "model": "llama3.2:1b"  // M√°s r√°pido, menos preciso
  "model": "mistral"      // Alternativa
  "model": "phi3"         // Muy ligero (1.5GB)
}
```

### Ajustar prompts

Cada workflow tiene un nodo "Consultar Ollama" con el prompt. Puedes editarlo para cambiar el comportamiento:

```javascript
"prompt": "Eres un asistente dom√≥tico. [Tu contexto aqu√≠]. Responde SOLO con JSON..."
```

**Tip:** Pide SIEMPRE que responda en formato JSON estructurado para que n8n pueda parsearlo f√°cilmente.

### A√±adir tus entidades

Sustituye las entidades de ejemplo (`light.salon`, `sensor.temperatura`, etc.) por las tuyas:

1. En Home Assistant, ve a Developer Tools ‚Üí States
2. Copia el `entity_id` exacto
3. Reemplaza en los workflows de n8n

## üêõ Troubleshooting

### Ollama no responde

```bash
# Verificar que el contenedor est√° corriendo
docker ps | grep ollama

# Ver logs
docker logs ollama

# Probar manualmente
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt": "Hola",
  "stream": false
}'
```

### n8n no puede conectar con Home Assistant

- Verifica que el token API es correcto
- Comprueba que CORS est√° habilitado en `configuration.yaml`
- Si usas HTTPS en HA, cambia la URL en credenciales n8n a `https://`

### Workflows no se activan

- Verifica que est√°n activados (toggle en la esquina superior derecha)
- Comprueba que las entidades existen en Home Assistant
- Revisa los logs de ejecuci√≥n en n8n (panel derecho)

### Error "JSON parse"

- El modelo de IA no est√° respondiendo en formato JSON v√°lido
- Edita el prompt y enfatiza: "Responde SOLAMENTE con JSON, sin texto adicional"
- Prueba con un modelo m√°s grande/preciso

## üìä Recursos del Sistema

**Consumo t√≠pico:**

- Home Assistant: ~200MB RAM
- n8n: ~150MB RAM
- Ollama (sin modelo cargado): ~100MB RAM
- Ollama con llama3.2 activo: ~2.5GB RAM
- Ollama-WebUI: ~100MB RAM

**Total:** ~3GB RAM con modelo activo, ~600MB en reposo

## üîí Seguridad

- Todos los servicios corren en red Docker local
- No se expone nada a internet (usa VPN o proxy reverso si necesitas acceso remoto)
- Los modelos LLM corren 100% local, tus datos no salen de tu red
- Considera a√±adir autenticaci√≥n a n8n en producci√≥n (variables de entorno en docker-compose)

## üåê Acceso Remoto (Opcional)

Si quieres acceder desde fuera de casa:

1. Usa [Nginx Proxy Manager](https://nginxproxymanager.com/) o [Traefik](https://traefik.io/)
2. Configura Let's Encrypt para HTTPS
3. Protege con autenticaci√≥n (Authelia, HTTP Basic Auth, etc.)
4. **NUNCA expongas Ollama directamente a internet**

## üìà Mejoras Futuras

Ideas para extender este proyecto:

- [ ] Workflow de resumen diario generado por IA
- [ ] Integraci√≥n con c√°maras para an√°lisis de im√°genes (detecci√≥n objetos, personas)
- [ ] Asistente conversacional completo (contexto multi-turno)
- [ ] Predicci√≥n de consumo energ√©tico con series temporales
- [ ] Recomendaciones proactivas ("Llueve, cierra las ventanas")

## ü§ù Contribuciones

Pull requests bienvenidas. Para cambios grandes, abre primero un issue.

## üìÑ Licencia

MIT

## üîó Enlaces √ötiles

- [Documentaci√≥n Home Assistant](https://www.home-assistant.io/docs/)
- [Documentaci√≥n n8n](https://docs.n8n.io/)
- [Modelos Ollama](https://ollama.com/library)
- [Art√≠culo completo en eldiarioia.es](https://www.eldiarioia.es/?p=2355)

---

**¬øPreguntas?** Abre un issue en este repositorio.

**¬øTe fue √∫til?** Dale una ‚≠ê al repo!
