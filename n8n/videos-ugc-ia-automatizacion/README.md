# Videos UGC con IA: AutomatizaciÃ³n con n8n y Stable Diffusion

## ğŸ“‹ DescripciÃ³n

Ejemplos de cÃ³digo y configuraciones del artÃ­culo publicado en [ElDiarioIA.es](https://www.eldiarioia.es).

Este repositorio contiene:
- Docker Compose completo para stack ComfyUI + n8n + FFmpeg
- Workflows n8n para automatizaciÃ³n de generaciÃ³n de videos UGC
- Scripts FFmpeg para procesamiento de video
- Scripts Python para generaciÃ³n batch

## ğŸ“ Estructura

```
videos-ugc-ia-automatizacion/
â”œâ”€â”€ docker-compose.yml          # Stack completo Docker
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create-video.sh         # Script bÃ¡sico FFmpeg
â”‚   â”œâ”€â”€ create-video-advanced.sh # Script avanzado con transiciones
â”‚   â””â”€â”€ generate-ugc-batch.py   # Script Python para batch
â”œâ”€â”€ n8n-workflows/
â”‚   â””â”€â”€ ugc-video-generator.json # Workflow n8n completo
â”œâ”€â”€ configs/                     # Configuraciones de ejemplo
â””â”€â”€ README.md                   # Este archivo
```

## ğŸš€ Uso RÃ¡pido

### 1. InstalaciÃ³n

```bash
# Clonar o descargar este repositorio
git clone https://github.com/ziruelen/learningaiagents.git
cd learningaiagents/n8n/videos-ugc-ia-automatizacion

# Crear directorios necesarios
mkdir -p comfyui_models/Stable-diffusion
mkdir -p comfyui_output
mkdir -p video_output

# Levantar servicios
docker-compose up -d
```

### 2. Descargar Modelo Stable Diffusion

```bash
# Descarga un modelo desde Civitai o Hugging Face a:
# comfyui_models/Stable-diffusion/
# Ejemplo: Realistic Vision v5
```

### 3. Generar Video con Python

```bash
# Instalar dependencias
pip install requests pillow

# Generar video
python3 scripts/generate-ugc-batch.py "a person unboxing a smartphone, authentic UGC style"
```

### 4. Usar Workflow n8n

1. Accede a n8n: http://localhost:5678
2. Importa el workflow: `n8n-workflows/ugc-video-generator.json`
3. Configura los prompts segÃºn tus necesidades
4. Activa el workflow

## ğŸ“– ArtÃ­culo Completo

Para instrucciones detalladas, troubleshooting y mejores prÃ¡cticas, consulta el artÃ­culo completo:

**ğŸ”— [Videos UGC con IA: Automatiza CreaciÃ³n de Contenido con n8n y Stable Diffusion](https://www.eldiarioia.es)**

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

Edita `docker-compose.yml` para personalizar:

- **Puertos**: Cambia `5678:5678` si el puerto estÃ¡ ocupado
- **Modelos**: Ajusta rutas de volÃºmenes segÃºn tu estructura
- **GPU**: Verifica que `nvidia` driver estÃ© configurado

### Requisitos

- Docker y Docker Compose
- GPU NVIDIA (recomendado, mÃ­nimo 4GB VRAM)
- FFmpeg instalado (o usar contenedor Docker)
- 16GB RAM mÃ­nimo
- 50GB espacio en disco (para modelos y videos)

## ğŸ› Troubleshooting

### FFmpeg no encuentra imÃ¡genes

```bash
# Verificar que las imÃ¡genes existen
ls -la comfyui_output/ugc_video_*.png

# Verificar permisos
chmod 644 comfyui_output/*.png
```

### Video sin audio

```bash
# AÃ±adir audio de fondo
ffmpeg -i video.mp4 -i audio.mp3 -c:v copy -c:a aac -shortest output.mp4
```

### ComfyUI no responde

```bash
# Verificar logs
docker logs comfyui

# Verificar puerto
curl http://localhost:8188/queue
```

## ğŸ“š Recursos

- [FFmpeg Documentation](https://ffmpeg.org/documentation.html)
- [n8n Documentation](https://docs.n8n.io/)
- [ComfyUI GitHub](https://github.com/comfyanonymous/ComfyUI)

## ğŸ“ Licencia

Estos ejemplos son de cÃ³digo abierto. Ãšsalos libremente en tus proyectos.

---

**Â¿Problemas?** Abre un issue en el repositorio o consulta el artÃ­culo completo.

